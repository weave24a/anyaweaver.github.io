[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to my Homepage!",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About this site",
    "section": "",
    "text": "About this site\nHi! My name is Anya, and I am a Senior at Mount Holyoke College. I am interested in machine learning and statistics!\n\n\n\n\n\n\n\n\n\nThis is an image of two views of the merlin protein, made in Pymol. It is a protein produced by the NF2 gene and is responsible for many cellular functions.\nTo contact me, please reach out via LinkedIn."
  },
  {
    "objectID": "Test.html",
    "href": "Test.html",
    "title": "Test",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "Test.html#quarto",
    "href": "Test.html#quarto",
    "title": "Test",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "Test.html#running-code",
    "href": "Test.html#running-code",
    "title": "Test",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "STAT244-HW1.html",
    "href": "STAT244-HW1.html",
    "title": "Assignment 1",
    "section": "",
    "text": "Getting Started\n\n\n\n\n\n\nAdd your name to the author field in the YAML header.\nMake sure you can render your document. The keyboard shortcut for rendering is Command+Shift+K for MacOS/Linux and Ctrl+Shift+K for Windows. For now, I recommend rendering to HTML."
  },
  {
    "objectID": "STAT244-HW1.html#configuring-rstudio-with-github",
    "href": "STAT244-HW1.html#configuring-rstudio-with-github",
    "title": "Assignment 1",
    "section": "Configuring RStudio with Github",
    "text": "Configuring RStudio with Github\nHere are the instructions for getting you started on using Github.\nPlease use the Mount Holyoke RStudio server (link: rstudio.mtholyoke.edu) to complete all of these tasks.\n\nWhy? The school server uses Linux, which means that the instructions I give (which are Linux-specific at times) will apply to all of you. If you choose to use R/RStudio on your personal laptop for connecting to Github, certain instructions will differ depending on whether your operating system is Windows or MacOS, so you will have to research what to do and/or make an appointment with me to set it up!\n\nIf you need to access the server off-campus (i.e., when not connected to MHC WiFi), then you will need to set up a VPN (instructions: here); come talk to Laura if you need help with this!\n\n\n\n\n\n\nExercise 1\n\n\n\n\n\nFor those that missed class on Wednesday Feb. 19th:\n\ngo to github.com and create an account associated with your Mount Holyoke email address (if you don’t have one already);\ngo through and follow the video Portfolio Part 1: Get Started with Github.\n\nFor those that attended class on Wed. Feb. 19th and\n\nsuccessfully created a README.md file, where\nREADME.md is in the same location as the .gitignore and your Rproj file (mine was called test_website.Rproj),\n\nyou should:\n\njump to 02:28 in Portfolio Part 2: Configure RStudio to Use Github and complete the video.\n\nThen complete Portfolio Part 3: Push to Github from RStudio, and be sure to read the accompanying instructions on Moodle!\nTo complete this exercise, your README.md should be pushed to Github.\n\nBy going to github.com/GITHUBUSERNAME/YOURWEBSITENAME.github.io, I should be able to see your README.md file rendered/displayed automatically.\n\n\nhttps://github.com/weave24a/anyaweaver.github.io\n\nOf course, there are easier ways to upload a single README to Github without going through the three video tutorials. The point of doing the process in the videos is to configure RStudio to easily push to Github to help you easily manage your portfolio website.\n\n\n\nIf at any point you run into issues, please email me (lalyman@mtholyoke.edu) before trying to research the problem and fix it yourself.\n\nWhy? Normally I love when students self-research to problem-solve, but it is easy to put this initial set-up into a state that is difficult to debug (especially for me, since I am not a computer scientist who is an expert on version control, HTTPS/SSH, digital signatures via generated keys, etc.)"
  },
  {
    "objectID": "STAT244-HW1.html#creating-functions-in-r",
    "href": "STAT244-HW1.html#creating-functions-in-r",
    "title": "Assignment 1",
    "section": "Creating Functions in R",
    "text": "Creating Functions in R\nIt is often good practice to define our own functions when coding. Some reasons are to:\n\navoid having a bunch of repeated code (often the case if you find yourself copy/pasting the same commands into separate code chunks only to, say, change a few numbers);\nimprove readability (since you are organizing your logic into separate, manageable pieces);\nmake debugging easier (since you can more easily isolate where an error is happening by testing each function individually).\n\nThe general syntax for writing a function in R is:\nyour_function_name &lt;- function(x,y,...) {\n  # Code for what the function returns\n}\nwhere x,y,... are whatever inputs you would like your function to depend on.\n\n\n\n\n\n\nExercise 2\n\n\n\n\n\nFinish the code in the chunk below to create a function named check_if_in_circle:\n\nThe function takes in an x and y coordinate.\nIt returns TRUE if (x,y) is within the unit circle (i.e., the circle of radius 1 centered at the origin), and it returns FALSE otherwise.\n\nNote that writing #| error: true at the start of a code chunk tells our document to render even if that chunk produces an error.\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n(x,y) is in unit circle \\(\\Leftrightarrow\\) \\(x^2 + y^2 \\le 1\\)\n\ncheck_if_in_circle &lt;- function(x,y) {\n  # YOUR CODE HERE\n  ifelse(x^2+y^2&lt;=1,TRUE, FALSE)\n}\n\n\n\n\nTo verify that the check_if_in_circle function is working correctly, run the following:\n\n# Should return TRUE\ncheck_if_in_circle(0, 0.99)\n\n[1] TRUE\n\n# Should return TRUE\ncheck_if_in_circle(-0.5, 0.5)\n\n[1] TRUE\n\n# Should return FALSE\ncheck_if_in_circle(1.1, 0.5)\n\n[1] FALSE\n\n# Should return FALSE\ncheck_if_in_circle(0.6, -0.85)\n\n[1] FALSE\n\n\nWithout doing anything different, we can notice that your code (by default!) also works when the inputs are (equally sized) lists \\((x_1, \\ldots, x_n)\\) and \\((y_1, \\ldots, y_n)\\) of x and y coordinates.\nIf given lists of coordinates, check_if_in_circle will return a list of booleans (i.e., TRUE/FALSE values), where the \\(i\\)th boolean is TRUE if \\((x_i, y_i)\\) is in the unit circle and FALSE otherwise.\n\n# List of x coordinates\nx_vec = c(0, -0.5, 1.1, 0.6) \n# List of y coordinates\ny_vec = c(0.99, 0.5, 0.5, -0.85)\n\n# Should return the list TRUE, TRUE, FALSE, FALSE, since\n# (0,0.99) and (-0.5, 0.5) are in the unit circle (as you just verified),\n# while (1.1, 0.5) and (0.6, -0.85) are not in the unit circle (as you\n# also just verified)\ncheck_if_in_circle(x_vec, y_vec)\n\n[1]  TRUE  TRUE FALSE FALSE\n\n\n\n\n\n\n\n\nExercise 3\n\n\n\n\n\nComplete the function return_color , which:\n\ntakes two lists x_vec = \\((x_1, \\ldots, x_n)\\) and y_vec = \\((y_1, \\ldots, y_n)\\) of x and y coordinates;\nreturns a list of the same length as x_vec and y_vec where each entry is either the string “blue” or the string “red”; namely, the \\(i\\)th entry is “blue” if \\((x_i, y_i)\\) is in the unit circle and is “red” otherwise.\n\n\nreturn_color &lt;- function(x_vec, y_vec) {\n  \n  ifelse(check_if_in_circle(x_vec,y_vec),\"blue\", \"red\")\n}\n\n\n# Should return \"blue\", \"blue\", \"red\", \"red\"\nreturn_color(x_vec, y_vec)\n\n[1] \"blue\" \"blue\" \"red\"  \"red\""
  },
  {
    "objectID": "STAT244-HW1.html#mc-simulation-estimating-the-area-of-a-region",
    "href": "STAT244-HW1.html#mc-simulation-estimating-the-area-of-a-region",
    "title": "Assignment 1",
    "section": "MC Simulation: Estimating the Area of a Region",
    "text": "MC Simulation: Estimating the Area of a Region\n\nVocabulary\n\nEvery time you generate random numbers (according to some probability model/distribution), this is called sampling from the distribution.\n\nFor example,\n\nwhen we run rnorm(1, mean = 0, sd = 1) we are sampling once from the standard normal distribution; i.e., sampling values from \\(X \\sim \\mathcal{N}(0,1)\\);\nwhen we run runif(n, a, b) we are sampling \\(n\\) times uniformly at random from the interval \\((a,b)\\); i.e., sampling values of \\(X \\sim U(a,b)\\); this means that \\(X\\) is equally likely to equal any value on the continuum between \\(a\\) and \\(b\\).\n\n\n\n\n\n\n\nExercise 4\n\n\n\n\n\nFill in the code below to sample points within the box \\([-1, 1] \\times [-1, 1]\\) uniformly at random. Hint. Look at your NotesDay3.qmd file (which you submitted on Moodle under Intro to Quarto Lab).\n\n# To make this code reproducible (same random number generated each time)\nset.seed(111)\n# Number of times to sample a point from the [-1,1] x [-1, 1] box\nnum_points = 100000\n\n# Sample x and y from the range [-1,1] uniformly at random\n# 100000 times\n\nx &lt;- runif(num_points, -1, 1)\ny &lt;- runif(num_points, -1, 1)\n  \n# The cbind() function takes two lists (of equal length) and puts them\n# into a table, where each list is a column of that table. The c stands\n# for \"column\" \ngenerated_data &lt;- data.frame(cbind(x, y))\n\n\n\n\nNow, when applied to a list of booleans (i.e., TRUE/FALSE values), the sum function will add up the number of TRUE values in the list. We can try this out below:\n\nlist_of_booleans = c(TRUE, FALSE, FALSE, TRUE, FALSE)\nsum(list_of_booleans)\n\n[1] 2\n\n\n\n\n\n\n\n\nExercise 5\n\n\n\n\n\nFill in the code below to estimate the value of \\(\\pi\\) according to this MC simulation using:\n\nthe sum function\nyour check_if_in_circle function\nx, y, and num_points from two code chunks above\nthe fact that the circle area = \\(\\pi\\cdot r^2\\) = \\(\\pi\\) for the unit circle.\n\nPlease try to figure this out without using external resources; otherwise, it ruins your chance to problem-solve! I am happy to help guide you – just ask!\n\nnum_pts_inside = sum(check_if_in_circle(x, y))\n\npi_estimate = 4*(num_pts_inside/num_points)\n\n\n\n\nIf successful, we can use our function return_color from before to visualize the process of marking whether points are included/excluded from the unit circle while displaying the corresponding pi_estimate. You should not need to modify the code in the chunk below.\n\n# Plot the points\nggplot(data = generated_data, \n       mapping = aes(x, y, col = return_color(x, y))) + \ngeom_point() + \nggtitle(paste(\"Estimated value of pi:\", pi_estimate)) +\ntheme(legend.position=\"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 6\n\n\n\n\n\nEstimate \\(\\pi\\) based instead on the upper right quarter of the unit circle rather than the whole circle. That is, sample uniformly at random in the box \\([0,1] \\times [0,1]\\) and consider when points land in the corresponding quarter of the unit circle centered at \\((0,0)\\).\nHints.\n\nInstead of check_if_in_circle, you will need a similar function that checks for whether input points fall in the upper right quadrant of the unit circle.\nYou will need to change how the runif function is called to select x and y.\nYour final calculation of pi_estimate might change slightly. (Do you still multiply by 4? Why?)\n\n\nset.seed(123)\n# Number of times to sample a point from the [0,1] x [0,1] box\nnum_points = 10000\ncheck_if_in_quadrant &lt;- function(x,y) {\n  ifelse(x^2+y^2&lt;=1,TRUE, FALSE)\n}\nx &lt;- runif(num_points, 0, 1)\ny &lt;- runif(num_points, 0, 1)\n\nnew_data &lt;- data.frame(cbind(x, y))\n\nAfter completing your code, include a visualization (like the one from the previous exercise) that displays how your algorithm is sampling and the \\(\\pi\\) estimate corresponding to that sampling.\n\nggplot(data = new_data, \n       mapping = aes(x, y, col = return_color(x, y))) + \ngeom_point() + \nggtitle(paste(\"Estimated value of pi:\", pi_estimate)) +\ntheme(legend.position=\"none\")\n\n\n\n\n\n\n\n# CODE FOR VISUALAIZATION HERE"
  },
  {
    "objectID": "Project Checkpoint 3.html",
    "href": "Project Checkpoint 3.html",
    "title": "Project Checkpoint 3: New Methodologies",
    "section": "",
    "text": "Due date: Thursday, May 1st @ 11:59 pm (You may use a 48 hour extension)\n\nIn this checkpoint, you’ll practice implementing the machine learning techniques you’ve been exposed to throughout this course. \nUse the ideas and techniques we’ve discussed in class to best answer the following questions. Do your best to answer in complete, thoughtful, and concise sentences. The more work you do here, the less work you have to do for your final paper. My intent is that 100% of the content in your paper and presentation comes from these project checkpoints. These checkpoints are graded based on (perceived) genuine effort rather than correctness. \nIf you are working in a group, while your group will submit only one final paper, each person must submit an individual project checkpoint (even if the checkpoints are identical). I will provide feedback on one person’s project checkpoints per group.\nCreate a Quarto file to answer the following questions. Do not answer simply using a Google Doc. You are required to do the section on Cross Validation (CV). You may then choose any of the following sections after that.\n\n\nCross Validation (CV) — Required\nOption: Variable Subset Selection\nOption: LASSO\nOption: Unsupervised Learning with K-Means Clustering\n\n\n\nResources:\n\nLab 6: Intro to Model Evaluation\nLab 7: k-Fold Cross Validation (CV)\nLab 7 Solutions\nSlides-Intro-CV-March10\nSection 5.1 in ISLR\n\n\nWrite a brief introduction to cross validation which includes relevant mathematical notation.\nCross validation is a method of training and testing statistical models for a dataset that does not come with a training data set. It is notated by the formula: E[Y|X] = β0 + β1X1+…+ βpXp, where Y is a random variable representing our outcome data, X is a random variable representing our input data, and E[Y|X] is the expected value of Y given input data X.\n\nWhat is the goal of cross-validation? (Hint: Think about over-fitting, along with social/ethical considerations) \nThe goal of cross-validation is to avoid overfitting, which is when a model constructed from a data set is so specific to that data that it cannot process any new data in the manner intended. This can cause problems if the training dataset has some bias, as it will reinforce that bias.\nWhat linear models are you considering based on your research question? Pick at least two models to compare.\nI am considering the three models:\nE[Earnings_median_5yr | Debt_median] = β0+ β1(Debt_median)\nE[Earnings_median_5yr | Earnings_median_1yr - Debt_median] = β0 - β1(Debt_median) + β2(Earnings_median_1yr)\nE[Earnings_median_5yr | Earnings_median_1yr] = β0+ β1(Earnings_median_1yr)\n\nExplain how you divided your data into its test set and training set.\n\nI divided my data into its test set and training set using 10-Fold CV.\n\nState which error metric you are using (MAE or MSE) and give its formal mathematical definition. Why did you choose this error metric? What are the advantages/disadvantages of using it?\n\nI chose MAE because my dataset includes outliers, and MAE uses the difference between the number the model predicts and the actual value of the testing data set in order to calculate the mean error. The formal definition of MAE is\n\nImplement k-fold cross validation for k = 10.\nDone\nDisplay evaluation metrics for your different models in a clean, organized way. This display should include both the estimated CV metric as well as its standard deviation.\n\n\n\nModel\n10-Fold CV MAE\nSD\n\n\n\n\n1\n7.663614e+03\n231.69329447\n\n\n2\n7.802707e+03\n322.35471344\n\n\n3\n7.802707e+03\n264.87574093\n\n\n\n\n\n\nTry different values of k (the tuning parameter). At minimum, try k = n - 1 (LOOCV), and k = 5. Which value of k has the smallest CV error?\n\nk=5 has the smallest error\n\nSelect your final model based on which one has the smallest CV error.\n\nModel 1 with k = 10 has the smallest CV error.\n\n\n\n\nResources:\n\nSlides-Subset-Selection\nLab 8: Variable Subset Selection\nLab 8 Solutions\nSection 6.1 in ISLR\n\n\nIdentify at least p = 3 predictors for modeling the expected response E(Y) of one of your variables Y.\n\nPredictors: Major, School Type, Earnings_Median_1yr, Debt\n\nState which error metric you are using (i.e., CV MAE or CV MSE and state the chosen k-value).\n\nCVMAE with k=10\n\nBest subset selection: Only implement this if you have under 100 rows/observations in your data set. Otherwise, skip this! It will be too computationally expensive!\nI currently have 239 rows, so I skipped this.\nBackward subset selection: Implement backward subset selection by starting with at least p = 3 predictors.\nDone\nWe have to pick a value for our tuning parameter (the number of predictors). Plot your cross validated error as a function of the number of predictors, where each model has predictors chosen based on your backward subset selection.\n\nCould not figure out how to do this but, my model narrowed down until both Earnings_median_1yr and Debt were left, but both had the same p-value (0). Would have to try another type of variable subse4t to narrow down further, or keep both.\n\n\nBased on your plot, which model do you pick?\n\nBased on my plot, I should pick a model that uses both Earnings_median_1yr, and Debt.\n\nWhy is backward subset selection a greedy algorithm? Answer in 1 - 3 sentences.\n\nBackward subset selection is a greedy algorithm because it takes out whichever variable changes the predicted value the most in each step."
  },
  {
    "objectID": "Project Checkpoint 3.html#table-of-contents",
    "href": "Project Checkpoint 3.html#table-of-contents",
    "title": "Project Checkpoint 3: New Methodologies",
    "section": "",
    "text": "Cross Validation (CV) — Required\nOption: Variable Subset Selection\nOption: LASSO\nOption: Unsupervised Learning with K-Means Clustering"
  },
  {
    "objectID": "Project Checkpoint 3.html#cross-validation-cv-required",
    "href": "Project Checkpoint 3.html#cross-validation-cv-required",
    "title": "Project Checkpoint 3: New Methodologies",
    "section": "",
    "text": "Resources:\n\nLab 6: Intro to Model Evaluation\nLab 7: k-Fold Cross Validation (CV)\nLab 7 Solutions\nSlides-Intro-CV-March10\nSection 5.1 in ISLR\n\n\nWrite a brief introduction to cross validation which includes relevant mathematical notation.\nCross validation is a method of training and testing statistical models for a dataset that does not come with a training data set. It is notated by the formula: E[Y|X] = β0 + β1X1+…+ βpXp, where Y is a random variable representing our outcome data, X is a random variable representing our input data, and E[Y|X] is the expected value of Y given input data X.\n\nWhat is the goal of cross-validation? (Hint: Think about over-fitting, along with social/ethical considerations) \nThe goal of cross-validation is to avoid overfitting, which is when a model constructed from a data set is so specific to that data that it cannot process any new data in the manner intended. This can cause problems if the training dataset has some bias, as it will reinforce that bias.\nWhat linear models are you considering based on your research question? Pick at least two models to compare.\nI am considering the three models:\nE[Earnings_median_5yr | Debt_median] = β0+ β1(Debt_median)\nE[Earnings_median_5yr | Earnings_median_1yr - Debt_median] = β0 - β1(Debt_median) + β2(Earnings_median_1yr)\nE[Earnings_median_5yr | Earnings_median_1yr] = β0+ β1(Earnings_median_1yr)\n\nExplain how you divided your data into its test set and training set.\n\nI divided my data into its test set and training set using 10-Fold CV.\n\nState which error metric you are using (MAE or MSE) and give its formal mathematical definition. Why did you choose this error metric? What are the advantages/disadvantages of using it?\n\nI chose MAE because my dataset includes outliers, and MAE uses the difference between the number the model predicts and the actual value of the testing data set in order to calculate the mean error. The formal definition of MAE is\n\nImplement k-fold cross validation for k = 10.\nDone\nDisplay evaluation metrics for your different models in a clean, organized way. This display should include both the estimated CV metric as well as its standard deviation.\n\n\n\nModel\n10-Fold CV MAE\nSD\n\n\n\n\n1\n7.663614e+03\n231.69329447\n\n\n2\n7.802707e+03\n322.35471344\n\n\n3\n7.802707e+03\n264.87574093\n\n\n\n\n\n\nTry different values of k (the tuning parameter). At minimum, try k = n - 1 (LOOCV), and k = 5. Which value of k has the smallest CV error?\n\nk=5 has the smallest error\n\nSelect your final model based on which one has the smallest CV error.\n\nModel 1 with k = 10 has the smallest CV error."
  },
  {
    "objectID": "Project Checkpoint 3.html#option-variable-subset-selection",
    "href": "Project Checkpoint 3.html#option-variable-subset-selection",
    "title": "Project Checkpoint 3: New Methodologies",
    "section": "",
    "text": "Resources:\n\nSlides-Subset-Selection\nLab 8: Variable Subset Selection\nLab 8 Solutions\nSection 6.1 in ISLR\n\n\nIdentify at least p = 3 predictors for modeling the expected response E(Y) of one of your variables Y.\n\nPredictors: Major, School Type, Earnings_Median_1yr, Debt\n\nState which error metric you are using (i.e., CV MAE or CV MSE and state the chosen k-value).\n\nCVMAE with k=10\n\nBest subset selection: Only implement this if you have under 100 rows/observations in your data set. Otherwise, skip this! It will be too computationally expensive!\nI currently have 239 rows, so I skipped this.\nBackward subset selection: Implement backward subset selection by starting with at least p = 3 predictors.\nDone\nWe have to pick a value for our tuning parameter (the number of predictors). Plot your cross validated error as a function of the number of predictors, where each model has predictors chosen based on your backward subset selection.\n\nCould not figure out how to do this but, my model narrowed down until both Earnings_median_1yr and Debt were left, but both had the same p-value (0). Would have to try another type of variable subse4t to narrow down further, or keep both.\n\n\nBased on your plot, which model do you pick?\n\nBased on my plot, I should pick a model that uses both Earnings_median_1yr, and Debt.\n\nWhy is backward subset selection a greedy algorithm? Answer in 1 - 3 sentences.\n\nBackward subset selection is a greedy algorithm because it takes out whichever variable changes the predicted value the most in each step."
  },
  {
    "objectID": "Project Checkpoint 3.html#option-lasso",
    "href": "Project Checkpoint 3.html#option-lasso",
    "title": "Project Checkpoint 3: New Methodologies",
    "section": "",
    "text": "Resources:\n\nLASSOIntro.pdf\nLab 9: LASSO\nLab 10: LASSO (Continued)\nSection 6.2.2 in ISLR\n\n\n\n\nWrite a brief introduction to LASSO which includes relevant mathematical notation.\n\n\n\nState which error metric you are using (i.e., CV MAE or CV MSE and state the chosen k-value).\n\n\n\n\n\nIdentify at least p = 3 predictors X1, X2, …, Xp for modeling the expected response E(Y) of one of your variables Y.\n\n\n\nCompute 50 LASSO models for 50 different values of 𝜆 (the penalty tuning parameter), each with all p predictors. You can start out by trying 𝜆 in the range of -5 to 1 on the log10 scale. Plot the cross-validated (CV) error for each value of 𝜆.\n\n\n\nBased on your plot in the previous step, what value of 𝜆 is best?\n\n\n\n\n\n\nPick the 𝜆 associated with the parsimonious model.\n\n\n\n\n\n\nFor your parsimonious model, how many and which predictors were kept?"
  },
  {
    "objectID": "Project Checkpoint 3.html#option-unsupervised-learning-with-k-means-clustering",
    "href": "Project Checkpoint 3.html#option-unsupervised-learning-with-k-means-clustering",
    "title": "Project Checkpoint 3: New Methodologies",
    "section": "",
    "text": "Resources:\n\nUnsupervised-Learning-K-Means\nLab 11: K-Means\nLab 11 Solutions (Partial)\nSection 12.4.1 in ISLR\n\n\n\n\n\nWrite a brief introduction to K-means which includes relevant mathematical notation.\n\n\n\nShow visuals to demonstrate your clustering.\n\n\n\nState which error metric you are using (MAE or MSE).\n\n\n\nInterpret the clusters qualitatively. That is, what does each cluster seem to represent intuitively?\n\n\n\nJustify the choice of the number of clusters (K) with Silhouette (e.g., see Lab 11)."
  },
  {
    "objectID": "STAT244-HW1_files/STAT244-HW1.html",
    "href": "STAT244-HW1_files/STAT244-HW1.html",
    "title": "Assignment 1",
    "section": "",
    "text": "Getting Started\n\n\n\n\n\n\nAdd your name to the author field in the YAML header.\nMake sure you can render your document. The keyboard shortcut for rendering is Command+Shift+K for MacOS/Linux and Ctrl+Shift+K for Windows. For now, I recommend rendering to HTML."
  },
  {
    "objectID": "STAT244-HW1_files/STAT244-HW1.html#configuring-rstudio-with-github",
    "href": "STAT244-HW1_files/STAT244-HW1.html#configuring-rstudio-with-github",
    "title": "Assignment 1",
    "section": "Configuring RStudio with Github",
    "text": "Configuring RStudio with Github\nHere are the instructions for getting you started on using Github.\nPlease use the Mount Holyoke RStudio server (link: rstudio.mtholyoke.edu) to complete all of these tasks.\n\nWhy? The school server uses Linux, which means that the instructions I give (which are Linux-specific at times) will apply to all of you. If you choose to use R/RStudio on your personal laptop for connecting to Github, certain instructions will differ depending on whether your operating system is Windows or MacOS, so you will have to research what to do and/or make an appointment with me to set it up!\n\nIf you need to access the server off-campus (i.e., when not connected to MHC WiFi), then you will need to set up a VPN (instructions: here); come talk to Laura if you need help with this!\n\n\n\n\n\n\nExercise 1\n\n\n\n\n\nFor those that missed class on Wednesday Feb. 19th:\n\ngo to github.com and create an account associated with your Mount Holyoke email address (if you don’t have one already);\ngo through and follow the video Portfolio Part 1: Get Started with Github.\n\nFor those that attended class on Wed. Feb. 19th and\n\nsuccessfully created a README.md file, where\nREADME.md is in the same location as the .gitignore and your Rproj file (mine was called test_website.Rproj),\n\nyou should:\n\njump to 02:28 in Portfolio Part 2: Configure RStudio to Use Github and complete the video.\n\nThen complete Portfolio Part 3: Push to Github from RStudio, and be sure to read the accompanying instructions on Moodle!\nTo complete this exercise, your README.md should be pushed to Github.\n\nBy going to github.com/GITHUBUSERNAME/YOURWEBSITENAME.github.io, I should be able to see your README.md file rendered/displayed automatically.\n\n\nhttps://github.com/weave24a/anyaweaver.github.io\n\nOf course, there are easier ways to upload a single README to Github without going through the three video tutorials. The point of doing the process in the videos is to configure RStudio to easily push to Github to help you easily manage your portfolio website.\n\n\n\nIf at any point you run into issues, please email me (lalyman@mtholyoke.edu) before trying to research the problem and fix it yourself.\n\nWhy? Normally I love when students self-research to problem-solve, but it is easy to put this initial set-up into a state that is difficult to debug (especially for me, since I am not a computer scientist who is an expert on version control, HTTPS/SSH, digital signatures via generated keys, etc.)"
  },
  {
    "objectID": "STAT244-HW1_files/STAT244-HW1.html#creating-functions-in-r",
    "href": "STAT244-HW1_files/STAT244-HW1.html#creating-functions-in-r",
    "title": "Assignment 1",
    "section": "Creating Functions in R",
    "text": "Creating Functions in R\nIt is often good practice to define our own functions when coding. Some reasons are to:\n\navoid having a bunch of repeated code (often the case if you find yourself copy/pasting the same commands into separate code chunks only to, say, change a few numbers);\nimprove readability (since you are organizing your logic into separate, manageable pieces);\nmake debugging easier (since you can more easily isolate where an error is happening by testing each function individually).\n\nThe general syntax for writing a function in R is:\nyour_function_name &lt;- function(x,y,...) {\n  # Code for what the function returns\n}\nwhere x,y,... are whatever inputs you would like your function to depend on.\n\n\n\n\n\n\nExercise 2\n\n\n\n\n\nFinish the code in the chunk below to create a function named check_if_in_circle:\n\nThe function takes in an x and y coordinate.\nIt returns TRUE if (x,y) is within the unit circle (i.e., the circle of radius 1 centered at the origin), and it returns FALSE otherwise.\n\nNote that writing #| error: true at the start of a code chunk tells our document to render even if that chunk produces an error.\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n(x,y) is in unit circle \\(\\Leftrightarrow\\) \\(x^2 + y^2 \\le 1\\)\n\ncheck_if_in_circle &lt;- function(x,y) {\n  # YOUR CODE HERE\n  ifelse(x^2+y^2&lt;=1,TRUE, FALSE)\n}\n\n\n\n\nTo verify that the check_if_in_circle function is working correctly, run the following:\n\n# Should return TRUE\ncheck_if_in_circle(0, 0.99)\n\n[1] TRUE\n\n# Should return TRUE\ncheck_if_in_circle(-0.5, 0.5)\n\n[1] TRUE\n\n# Should return FALSE\ncheck_if_in_circle(1.1, 0.5)\n\n[1] FALSE\n\n# Should return FALSE\ncheck_if_in_circle(0.6, -0.85)\n\n[1] FALSE\n\n\nWithout doing anything different, we can notice that your code (by default!) also works when the inputs are (equally sized) lists \\((x_1, \\ldots, x_n)\\) and \\((y_1, \\ldots, y_n)\\) of x and y coordinates.\nIf given lists of coordinates, check_if_in_circle will return a list of booleans (i.e., TRUE/FALSE values), where the \\(i\\)th boolean is TRUE if \\((x_i, y_i)\\) is in the unit circle and FALSE otherwise.\n\n# List of x coordinates\nx_vec = c(0, -0.5, 1.1, 0.6) \n# List of y coordinates\ny_vec = c(0.99, 0.5, 0.5, -0.85)\n\n# Should return the list TRUE, TRUE, FALSE, FALSE, since\n# (0,0.99) and (-0.5, 0.5) are in the unit circle (as you just verified),\n# while (1.1, 0.5) and (0.6, -0.85) are not in the unit circle (as you\n# also just verified)\ncheck_if_in_circle(x_vec, y_vec)\n\n[1]  TRUE  TRUE FALSE FALSE\n\n\n\n\n\n\n\n\nExercise 3\n\n\n\n\n\nComplete the function return_color , which:\n\ntakes two lists x_vec = \\((x_1, \\ldots, x_n)\\) and y_vec = \\((y_1, \\ldots, y_n)\\) of x and y coordinates;\nreturns a list of the same length as x_vec and y_vec where each entry is either the string “blue” or the string “red”; namely, the \\(i\\)th entry is “blue” if \\((x_i, y_i)\\) is in the unit circle and is “red” otherwise.\n\n\nreturn_color &lt;- function(x_vec, y_vec) {\n  \n  ifelse(check_if_in_circle(x_vec,y_vec),\"blue\", \"red\")\n}\n\n\n# Should return \"blue\", \"blue\", \"red\", \"red\"\nreturn_color(x_vec, y_vec)\n\n[1] \"blue\" \"blue\" \"red\"  \"red\""
  },
  {
    "objectID": "STAT244-HW1_files/STAT244-HW1.html#mc-simulation-estimating-the-area-of-a-region",
    "href": "STAT244-HW1_files/STAT244-HW1.html#mc-simulation-estimating-the-area-of-a-region",
    "title": "Assignment 1",
    "section": "MC Simulation: Estimating the Area of a Region",
    "text": "MC Simulation: Estimating the Area of a Region\n\nVocabulary\n\nEvery time you generate random numbers (according to some probability model/distribution), this is called sampling from the distribution.\n\nFor example,\n\nwhen we run rnorm(1, mean = 0, sd = 1) we are sampling once from the standard normal distribution; i.e., sampling values from \\(X \\sim \\mathcal{N}(0,1)\\);\nwhen we run runif(n, a, b) we are sampling \\(n\\) times uniformly at random from the interval \\((a,b)\\); i.e., sampling values of \\(X \\sim U(a,b)\\); this means that \\(X\\) is equally likely to equal any value on the continuum between \\(a\\) and \\(b\\).\n\n\n\n\n\n\n\nExercise 4\n\n\n\n\n\nFill in the code below to sample points within the box \\([-1, 1] \\times [-1, 1]\\) uniformly at random. Hint. Look at your NotesDay3.qmd file (which you submitted on Moodle under Intro to Quarto Lab).\n\n# To make this code reproducible (same random number generated each time)\nset.seed(111)\n# Number of times to sample a point from the [-1,1] x [-1, 1] box\nnum_points = 100000\n\n# Sample x and y from the range [-1,1] uniformly at random\n# 100000 times\n\nx &lt;- runif(num_points, -1, 1)\ny &lt;- runif(num_points, -1, 1)\n  \n# The cbind() function takes two lists (of equal length) and puts them\n# into a table, where each list is a column of that table. The c stands\n# for \"column\" \ngenerated_data &lt;- data.frame(cbind(x, y))\n\n\n\n\nNow, when applied to a list of booleans (i.e., TRUE/FALSE values), the sum function will add up the number of TRUE values in the list. We can try this out below:\n\nlist_of_booleans = c(TRUE, FALSE, FALSE, TRUE, FALSE)\nsum(list_of_booleans)\n\n[1] 2\n\n\n\n\n\n\n\n\nExercise 5\n\n\n\n\n\nFill in the code below to estimate the value of \\(\\pi\\) according to this MC simulation using:\n\nthe sum function\nyour check_if_in_circle function\nx, y, and num_points from two code chunks above\nthe fact that the circle area = \\(\\pi\\cdot r^2\\) = \\(\\pi\\) for the unit circle.\n\nPlease try to figure this out without using external resources; otherwise, it ruins your chance to problem-solve! I am happy to help guide you – just ask!\n\nnum_pts_inside = sum(check_if_in_circle(x, y))\n\npi_estimate = 4*(num_pts_inside/num_points)\n\n\n\n\nIf successful, we can use our function return_color from before to visualize the process of marking whether points are included/excluded from the unit circle while displaying the corresponding pi_estimate. You should not need to modify the code in the chunk below.\n\n# Plot the points\nggplot(data = generated_data, \n       mapping = aes(x, y, col = return_color(x, y))) + \ngeom_point() + \nggtitle(paste(\"Estimated value of pi:\", pi_estimate)) +\ntheme(legend.position=\"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 6\n\n\n\n\n\nEstimate \\(\\pi\\) based instead on the upper right quarter of the unit circle rather than the whole circle. That is, sample uniformly at random in the box \\([0,1] \\times [0,1]\\) and consider when points land in the corresponding quarter of the unit circle centered at \\((0,0)\\).\nHints.\n\nInstead of check_if_in_circle, you will need a similar function that checks for whether input points fall in the upper right quadrant of the unit circle.\nYou will need to change how the runif function is called to select x and y.\nYour final calculation of pi_estimate might change slightly. (Do you still multiply by 4? Why?)\n\n\nset.seed(123)\n# Number of times to sample a point from the [0,1] x [0,1] box\nnum_points = 10000\ncheck_if_in_quadrant &lt;- function(x,y) {\n  ifelse(x^2+y^2&lt;=1,TRUE, FALSE)\n}\nx &lt;- runif(num_points, 0, 1)\ny &lt;- runif(num_points, 0, 1)\n\nnew_data &lt;- data.frame(cbind(x, y))\n\nAfter completing your code, include a visualization (like the one from the previous exercise) that displays how your algorithm is sampling and the \\(\\pi\\) estimate corresponding to that sampling.\n\nggplot(data = new_data, \n       mapping = aes(x, y, col = return_color(x, y))) + \ngeom_point() + \nggtitle(paste(\"Estimated value of pi:\", pi_estimate)) +\ntheme(legend.position=\"none\")\n\n\n\n\n\n\n\n# CODE FOR VISUALAIZATION HERE"
  },
  {
    "objectID": "FPCP1.html",
    "href": "FPCP1.html",
    "title": "Final Project: Checkpoint 1",
    "section": "",
    "text": "1. Review the Final Project Description document}.\n\n\n2. Describe your data set in 1 - 2 sentences.\nMy dataset is a set of data about the universities, degree statuses, debt, and earnings of Biochemistry, Biophysics and Molecular Biology students.\n\n\n3. What is the source of your data set? Include a link to where you got it here.\nMy data was extracted from the Most Recent Data by field of study dataset from the College Scorecard project. Here is the link: https://collegescorecard.ed.gov/data\nNote. If you would like to collect survey data from classmates or peers via a Google form, please let me know right away so we can set this up for you. In the meantime, create the Google Form and decide what information you want to collect.\nThe following questions allow us to determine if your proposed data set meets the project criterion:\n\n\n4. Load your data set using the code chunk below.\n\nbiochem = read_csv(\"biochem.csv\")\n\nRows: 1140 Columns: 174\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (167): OPEID6, INSTNM, CONTROL, major, CREDDESC, DEBT_ALL_STGP_ANY_N, DE...\ndbl   (7): UNITID, MAIN, CIPCODE, CREDLEV, IPEDSCOUNT1, IPEDSCOUNT2, DISTANCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n5. How many rows does your data set have? There should be at least 30 rows.\nThere are currently 1140 rows. I will likely decrease this by removing rows with no integer response to the columns that are supposed to have an integer response.\n\n\n6. How many quantitative variables are in your data set? There should be at least 3. List them here and briefly describe what they represent and their units.\nI currently have 166 quantitative variables in my data set. My goal is to filter these into somewhere between 4 and 10 variables. one of the variables increases in whole numbers from 1-6 and represents the level of degree earned from the institution. The rest of the variables that I am considering keeping represent various permutations (various variables quantify them, and I am deciding which ones to keep) of the amount (mean and median) of debt aquired by students, the amount of loan money granted to students, and the earnings of students. These are all positive integers that represent dollar amounts.\nIf there are more than (say) 5 quantitative variables in your data set, you only need to list the ones you would like to consider. You can of course decide to consider other variables later; your choices in the checkpoints are not binding.\n\n\n7. How many categorical variables does your data set have? There should be at least 1. List the categorical variable(s) here along with their corresponding categories.\nMy dataset has 7 categorical variables. I am currently interested in considering INSTNM, which is the name of the colleges, CONTROL, which is who owns the colleges, and MAIN, which is if the students attended the main campus.\nIf there are more than (say) 3 categorical variables in your data set, you only need to list the ones you would like to consider. You can of course decide to consider other variables later; your choices in the checkpoints are not binding."
  },
  {
    "objectID": "DatasetEvalFinalProject.html",
    "href": "DatasetEvalFinalProject.html",
    "title": "Data Evaluation for Final Project",
    "section": "",
    "text": "Setup file\nLoad dataset of interest:\n\n#commented out because I made a new CSV\n#field = read_csv(\"Field.csv\")\n\nRename CIPDESC to major for clarity:\n\n#field = rename(field, Major = CIPDESC)\n\nAsses contents of Dataset:\n\n#head(field)\n\nSort by Major to asses options:\n\n# commented out b/c it takes a while, makes a lot of data, and I don't need to do it again\n#table(field$major)\n\nMutate Dataset to only include Biology, General and Biochemistry, Biophysics and Molecular Biology Majors & rename those majors to biology and biochem+:\n\n#field = field  %&gt;% mutate(Major = ifelse(Major == 'Biochemistry, Biophysics and Molecular Biology.', \"biochem+\", Major))\n\n#field = field  %&gt;% mutate(Major = ifelse(Major == 'Biology, General.', \"biology\", Major))\n\n#bio &lt;- field %&gt;% filter((Major == 'biochem+') | (Major == 'biology'))\n\n#bio &lt;- bio %&gt;% mutate(Major = as.factor(Major))\n\nTurn new dataset into its own CSV so I don’t have to load field again:\n\n#commented out because I only need the one CSV\n#write_csv(bio, \"bio.csv\")\n#bio = read_csv(\"bio.csv\")\n\nMutate Dataset to only include some variables:\n\n#figure out what column names translate to the columns DEBTMEDIAN, DEBTMEAN, and MD_EARN_WNE. Figure out how gender comes into it. \n\n# bio &lt;- bio %&gt;% select(Major, INSTNM, CONTROL, CREDDESC, DEBT_ALL_PP_EVAL_MDN, DEBT_ALL_STGP_EVAL_MDN, EARN_MDN_HI_1YR, DISTANCE, EARN_MDN_5YR)\n# head(bio)\n\nFilter out non responses:\n\n# bio = bio %&gt;% filter(!is.na(DEBT_ALL_PP_EVAL_MDN) & (DEBT_ALL_PP_EVAL_MDN !=\"PS\"))\n\nAdd STGPand PP together to make one value for debt:\n\n# bio$DEBT_ALL_PP_EVAL_MDN = as.numeric(bio$DEBT_ALL_PP_EVAL_MDN)\n# bio$DEBT_ALL_STGP_EVAL_MDN = as.numeric(bio$DEBT_ALL_STGP_EVAL_MDN)\n# bio$Debt_median &lt;- bio$DEBT_ALL_PP_EVAL_MDN + bio$DEBT_ALL_STGP_EVAL_MDN\n\nRename included variables for clarity:\n\n# bio = rename(bio, Institution = INSTNM)\n# bio = rename(bio, School_type = CONTROL)\n# bio = rename(bio, Degree = CREDDESC)\n# bio = rename(bio, Distance = DISTANCE)\n# bio = rename(bio, Earnings_median_1yr = EARN_MDN_HI_1YR)\n# bio = rename(bio, Earnings_median_5yr = EARN_MDN_5YR)\n\nRemove old columns:\n\n# bio &lt;- bio %&gt;% select(Major, Institution, \n#                           School_type, Degree, Debt_median, Distance, Earnings_median_1yr, Earnings_median_5yr)\n# head(bio)\n\nFilter out NAs:\n\n# bio$Earnings_median_1yr = as.numeric(bio$Earnings_median_1yr)\n# bio$Earnings_median_5yr = as.numeric(bio$Earnings_median_5yr)\n\nMake sure quantitative variables are recorded as numbers:\n\n# bio = bio %&gt;% filter(!is.na(Earnings_median_1yr) & (Earnings_median_5yr !=\"PS\"))\n# bio$Earnings_median_1yr = as.numeric(bio$Earnings_median_1yr)\n# bio$Earnings_median_5yr = as.numeric(bio$Earnings_median_5yr)\n\nRead Bio:\n\n# write_csv(bio, \"bio.csv\")\nbio = read_csv(\"bio.csv\")\n\nRows: 329 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): Major, Institution, School_type, Degree\ndbl (4): Debt_median, Distance, Earnings_median_1yr, Earnings_median_5yr\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nAnalyze Quantitative Variables:\n\nmean(bio$Debt_median)\n\n[1] 56783.04\n\nsd(bio$Debt_median)\n\n[1] 19378.69\n\nmean(bio$Earnings_median_1yr)\n\n[1] 27300.29\n\nsd(bio$Earnings_median_1yr)\n\n[1] 4747.215\n\nmean(bio$Earnings_median_5yr)\n\n[1] 62974.57\n\nsd(bio$Earnings_median_5yr)\n\n[1] 10156.37\n\n\nAnalyze Qualitative Variables:\n\ncount(bio$Institution)\n\nn_Alabama A & M University \n                         1 \n\ncount(bio$School_type)\n\nn_Private, for-profit \n                    1 \n\ncount(bio$Degree)\n\nn_Bachelor's Degree \n                329 \n\ncount(bio$Distance)\n\nn_1 \n318 \n\n\nProduce data visualizations\n\nbio %&gt;%\nggplot(aes(x = Debt_median, y = Earnings_median_5yr)) +\ngeom_point() +\nlabs(x = 'Median Debt ($)', y = 'Median Earnings 5 Years After Graduation ($)') +\ntheme_classic()\n\n\n\n\n\n\n\nbio %&gt;%\nggplot(aes(x = Earnings_median_1yr, y = Earnings_median_5yr)) +\ngeom_point() +\nlabs(x = 'Median Earnings 1 Year After Graduation ($)', y = 'Median Earnings 5 Years After Graduation ($)') +\ntheme_classic()\n\n\n\n\n\n\n\nbio %&gt;%\nggplot(aes(x = Debt_median, y = Earnings_median_1yr)) +\ngeom_point() +\nlabs(x = 'Median Debt ($', y = 'Median Earnings 1 Year After Graduation ($)') +\ntheme_classic()\n\n\n\n\n\n\n\n\nHistograms for dataset:\nHistograms for dataset:\nHistograms for dataset:\nHistograms for dataset:"
  },
  {
    "objectID": "STAT 244-SC.html",
    "href": "STAT 244-SC.html",
    "title": "STAT 244-SC",
    "section": "",
    "text": "This webpage will have the results of my final project for STAT 244-SC. I am analyzing the link between student debt and median earnings 1 and 5 years after graduation for biochemistry and biology majors according to the College Scorecard project."
  },
  {
    "objectID": "STAT 244-SC.html#quarto",
    "href": "STAT 244-SC.html#quarto",
    "title": "STAT 244-SC",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "STAT 244-SC.html#running-code",
    "href": "STAT 244-SC.html#running-code",
    "title": "STAT 244-SC",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "STAT 244-SC.html#final-project",
    "href": "STAT 244-SC.html#final-project",
    "title": "STAT 244-SC",
    "section": "",
    "text": "This webpage will have the results of my final project for STAT 244-SC. I am analyzing the link between student debt and median earnings 1 and 5 years after graduation for biochemistry and biology majors according to the College Scorecard project."
  },
  {
    "objectID": "STAT 244-SC.html#basic-information",
    "href": "STAT 244-SC.html#basic-information",
    "title": "STAT 244-SC",
    "section": "Basic Information",
    "text": "Basic Information\nHere are some figures that provide an introduction to the dataset I am analyzing.\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "STAT-244-SC.html",
    "href": "STAT-244-SC.html",
    "title": "STAT 244-SC",
    "section": "",
    "text": "This webpage will have the results of my final project for STAT 244-SC. I am analyzing the link between student debt and median earnings 1 and 5 years after graduation for biochemistry and biology majors according to the College Scorecard project."
  },
  {
    "objectID": "STAT-244-SC.html#final-project",
    "href": "STAT-244-SC.html#final-project",
    "title": "STAT 244-SC",
    "section": "",
    "text": "This webpage will have the results of my final project for STAT 244-SC. I am analyzing the link between student debt and median earnings 1 and 5 years after graduation for biochemistry and biology majors according to the College Scorecard project."
  },
  {
    "objectID": "STAT-244-SC.html#basic-information",
    "href": "STAT-244-SC.html#basic-information",
    "title": "STAT 244-SC",
    "section": "Basic Information",
    "text": "Basic Information\nHere are some figures that provide an introduction to the dataset I am analyzing.\n\nbio %&gt;%\nggplot(aes(x = Debt_median, y = Earnings_median_5yr)) +\ngeom_point() +\nlabs(x = 'Median Debt ($)', y = 'Median Earnings 5 Years After Graduation ($)') +\ntheme_classic()\n\n\n\n\n\n\n\nbio %&gt;%\nggplot(aes(x = Earnings_median_1yr, y = Earnings_median_5yr)) +\ngeom_point() +\nlabs(x = 'Median Earnings 1 Year After Graduation ($)', y = 'Median Earnings 5 Years After Graduation ($)') +\ntheme_classic()\n\n\n\n\n\n\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "FinalDataEval.html",
    "href": "FinalDataEval.html",
    "title": "Data Evaluation for Final Project",
    "section": "",
    "text": "Setup file\nLoad dataset of interest:\n\n#commented out because I made a new CSV\n#field = read_csv(\"Field.csv\")\n\nRename CIPDESC to major for clarity:\n\n#field = rename(field, Major = CIPDESC)\n\nAsses contents of Dataset:\n\n#head(field)\n\nSort by Major to asses options:\n\n# commented out b/c it takes a while, makes a lot of data, and I don't need to do it again\n#table(field$major)\n\nMutate Dataset to only include Biology, General and Biochemistry, Biophysics and Molecular Biology Majors & rename those majors to biology and biochem+:\n\n#field = field  %&gt;% mutate(Major = ifelse(Major == 'Biochemistry, Biophysics and Molecular Biology.', \"biochem+\", Major))\n\n#field = field  %&gt;% mutate(Major = ifelse(Major == 'Biology, General.', \"biology\", Major))\n\n#bio &lt;- field %&gt;% filter((Major == 'biochem+') | (Major == 'biology'))\n\n#bio &lt;- bio %&gt;% mutate(Major = as.factor(Major))\n\nTurn new dataset into its own CSV so I don’t have to load field again:\n\n#commented out because I only need the one CSV\n#write_csv(bio, \"bio.csv\")\n#bio = read_csv(\"bio.csv\")\n\nMutate Dataset to only include some variables:\n\n#figure out what column names translate to the columns DEBTMEDIAN, DEBTMEAN, and MD_EARN_WNE. Figure out how gender comes into it. \n\n# bio &lt;- bio %&gt;% select(Major, INSTNM, CONTROL, CREDDESC, DEBT_ALL_PP_EVAL_MDN, DEBT_ALL_STGP_EVAL_MDN, EARN_MDN_HI_1YR, DISTANCE, EARN_MDN_5YR)\n# head(bio)\n\nFilter out non responses:\n\n# bio = bio %&gt;% filter(!is.na(DEBT_ALL_PP_EVAL_MDN) & (DEBT_ALL_PP_EVAL_MDN !=\"PS\"))\n\nAdd STGPand PP together to make one value for debt:\n\n# bio$DEBT_ALL_PP_EVAL_MDN = as.numeric(bio$DEBT_ALL_PP_EVAL_MDN)\n# bio$DEBT_ALL_STGP_EVAL_MDN = as.numeric(bio$DEBT_ALL_STGP_EVAL_MDN)\n# bio$Debt_median &lt;- bio$DEBT_ALL_PP_EVAL_MDN + bio$DEBT_ALL_STGP_EVAL_MDN\n\nRename included variables for clarity:\n\n# bio = rename(bio, Institution = INSTNM)\n# bio = rename(bio, School_type = CONTROL)\n# bio = rename(bio, Degree = CREDDESC)\n# bio = rename(bio, Distance = DISTANCE)\n# bio = rename(bio, Earnings_median_1yr = EARN_MDN_HI_1YR)\n# bio = rename(bio, Earnings_median_5yr = EARN_MDN_5YR)\n\nRemove old columns:\n\n# bio &lt;- bio %&gt;% select(Major, Institution, \n#                           School_type, Degree, Debt_median, Distance, Earnings_median_1yr, Earnings_median_5yr)\n# head(bio)\n\nFilter out NAs:\n\n# bio$Earnings_median_1yr = as.numeric(bio$Earnings_median_1yr)\n# bio$Earnings_median_5yr = as.numeric(bio$Earnings_median_5yr)\n\nMake sure quantitative variables are recorded as numbers:\n\n# bio = bio %&gt;% filter(!is.na(Earnings_median_1yr) & (Earnings_median_5yr !=\"PS\"))\n# bio$Earnings_median_1yr = as.numeric(bio$Earnings_median_1yr)\n# bio$Earnings_median_5yr = as.numeric(bio$Earnings_median_5yr)\n\nRead Bio:\n\n# write_csv(bio, \"bio.csv\")\nbio = read_csv(\"bio.csv\")\n\nAnalyze Quantitative Variables:\n\nmean(bio$Debt_median)\n\n[1] 56783.04\n\nsd(bio$Debt_median)\n\n[1] 19378.69\n\nmean(bio$Earnings_median_1yr)\n\n[1] 27300.29\n\nsd(bio$Earnings_median_1yr)\n\n[1] 4747.215\n\nmean(bio$Earnings_median_5yr)\n\n[1] 62974.57\n\nsd(bio$Earnings_median_5yr)\n\n[1] 10156.37\n\n\nAnalyze Qualitative Variables:\n\ncount(bio$Institution)\n\nn_Alabama A & M University \n                         1 \n\ncount(bio$School_type)\n\nn_Private, for-profit \n                    1 \n\ncount(bio$Degree)\n\nn_Bachelor's Degree \n                329 \n\ncount(bio$Distance)\n\nn_1 \n318 \n\n\nProduce data visualizations\n\nbio %&gt;%\nggplot(aes(x = Debt_median, y = Earnings_median_5yr)) +\ngeom_point() +\nlabs(x = 'Median Debt ($)', y = 'Median Earnings 5 Years After Graduation ($)') +\ntheme_classic()\n\n\n\n\n\n\n\nbio %&gt;%\nggplot(aes(x = Earnings_median_1yr, y = Earnings_median_5yr)) +\ngeom_point() +\nlabs(x = 'Median Earnings 1 Year After Graduation ($)', y = 'Median Earnings 5 Years After Graduation ($)') +\ntheme_classic()\n\n\n\n\n\n\n\nbio %&gt;%\nggplot(aes(x = Debt_median, y = Earnings_median_1yr)) +\ngeom_point() +\nlabs(x = 'Median Debt ($', y = 'Median Earnings 1 Year After Graduation ($)') +\ntheme_classic()\n\n\n\n\n\n\n\n\nHistograms for dataset:"
  }
]